{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e433e6ed",
   "metadata": {},
   "source": [
    "You must have gone through the terms like Accuracy, F1 Score, Confusion Matrix, Precision and Recall while evaluating the performance of your machine learning model. In this article, I will take you through what is Accuracy, F1 Score, Confusion Matrix, Precision and Recall in Machine Learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784e2fd8",
   "metadata": {},
   "source": [
    "# Introduction to Accuracy, F1 Score, Confusion Matrix, Precision and Recall\n",
    "\n",
    "After training a machine learning model, letâ€™s say a classification model with class labels 0 and 1, the next step we need to do is make predictions on the test data. To find out how well our model works on the test data, we usually print a confusion matrix."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ed3df78",
   "metadata": {},
   "source": [
    "\n",
    "confusion matrix\n",
    "TP means True Positive\n",
    "FP means False Positive\n",
    "TN means True Negative\n",
    "FN means False Negative\n",
    "As you can see in the title of the figure above it is represented by two terms; Actual values and Predicted values, which leads to the introduction of all other factors of performance evaluation metrics like Accuracy, F1 Score, Precision and R"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f577344d",
   "metadata": {},
   "source": [
    "As you can see in the title of the figure above it is represented by two terms; Actual values and Predicted values, which leads to the introduction of all other factors of performance evaluation metrics like Accuracy, F1 Score, Precision and Recall.\n",
    "Accuracy is the ratio of the True predicted values to the Total predicted values. Accuracy = (True Positive + True Negative) / (True Positive + False Positive + True Negative + False Negative).\n",
    "\n",
    "The precision for class 1 is, out of all predicted class values like 1, how many actually belong to class 1. Precision = TP / (TP + FP).\n",
    "\n",
    "Recall for class 1 is, out of all the values that actually belong to class 1, how much is predicted as class 1. Recall = TP / (TP + FN).\n",
    "\n",
    "Since there is a trade-off between precision and recall, this means that if one increases, the other decreases. Sometimes accuracy alone is not a good idea to use as an evaluation measure. This is the reason why we use precision and recall in consideration.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b0771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "To have a combined effect of precision and recall, we use the F1 score. The F1 score is the harmonic mean of precision and recall. F1 score = 2 / (1 / Precision + 1 / Recall).\n",
    "\n",
    "I hope you liked this article on the concept of Performance Evaluation matrics of a Machine Learning mode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
